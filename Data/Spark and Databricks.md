

### Apache Spark

Is an open-source framework for distributed data processing. Anyone who uses the Spark ecosystem in an application can focus on his/her domain-specific data processing business case, while trusting that Spark will handle the messy details of parallel computing.

Spark is deployed as a cluster consisting of a master server and many worker servers. The master server accepts incoming jobs and breaks them down into smaller tasks that can be handled by workers.

 Spark isn't a data storage solution, neither a Hadoop replacement.

#### Dataframe

One of the core API's of Apache Spark is the DataFrame. It represents a table of data with rows and columns.

The list of columns and the respective datatypes are what's called the schema.
Like an Excel spreadsheet with named columns.

DataFrames are powerful and can be partitioned across thousands of computers at the same time.

### Databricks

Databricks is an Apache Spark-based analytics platform optimized either AWS or Azure platforms.

Designed with the founders of Apache Spark, Databricks is integrated in these cloud providers to provide one-click setup, streamlined workflows, and an interactive workspace that enables collaboration between data scientist, data engineers, and business analysts.

There is also a free community edition available where you can learn the basics!



## References

https://dev.to/hugoestradas/apache-spark-and-databricks-101-pt-i-the-big-picture-3gjc

